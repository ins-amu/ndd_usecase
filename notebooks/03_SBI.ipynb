{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "606c600b-eb5f-435a-a629-42b7ed713fae",
   "metadata": {},
   "source": [
    "# Simulation Based Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79550766-aa81-438f-a481-7d1839a492f3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "395d664a-97b4-4c4e-8c53-fd5d3d2767f7",
   "metadata": {},
   "source": [
    "## Simulation configuration and priors\n",
    "\n",
    "We start with configuring a TVB simulator instance which will serve as a template for the inference, here we take the same setup as in the previous notebooks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fdc28b-088d-48b1-8b17-af6650f1d106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tvb.simulator.lab import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9906e312-e640-44b6-915c-ca9fcc458709",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tvb_inversion.utils import init_experiment, data_path\n",
    "from tvb_inversion.parameters import SimSeq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02b6330b-b200-49a4-8834-32ac0436e3c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "seq = SimSeq(\n",
    "    template = simulator.Simulator(\n",
    "        model=mpr,\n",
    "        connectivity=conn,\n",
    "        coupling=coupling.Linear(),\n",
    "        integrator=integrators.HeunStochastic(\n",
    "            dt=0.01,\n",
    "            noise=noise.Additive(nsig=0.037*np.r_[1,2])\n",
    "        ),\n",
    "        monitors=[monitors.TemporalAverage(period=.1)]                \n",
    "    ).configure(),\n",
    "    params=['coupling.a'],\n",
    "    values=[\n",
    "        [\n",
    "            np.r_[a],                           # coupling scaling G\n",
    "        ] \n",
    "        for a in np.arange(0.5, 1.2,0.05)       # list of values of G\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a7483a-a415-4fbf-acab-b013333d7e18",
   "metadata": {},
   "source": [
    "Next, we define the prior distribution for the parameters we want to subject to inference using the `Prior` class from the `tvb-inversion` package. Here a two-dimensional uniform prior is given for the coupling strength parameter, and the $\\eta_{limbic}$ value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c97b0cf-d6f9-495c-8ee5-047a0a2cb0db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tvb_inversion.sbi import Prior\n",
    "import torch\n",
    "\n",
    "prior = Prior(['coupling.a'], torch.distributions.Uniform(0.1, 1.2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e27d60a9-25b8-40d5-b948-b8b77a3c9e52",
   "metadata": {},
   "source": [
    "## Sampling, running simulations\n",
    "\n",
    "Here we follow the same steps as in the case of parameter sweeps. We could run the simulations locally using following the local parallel runner as shown below, or use the distributed runner as in the previous examples.\n",
    "\n",
    "```python\n",
    "import utils\n",
    "\n",
    "utils.run_local(seq, metrics, backend=NbMPRBackend, checkpoint_dir='test_run', filename='results.npy')\n",
    "```\n",
    "\n",
    "\n",
    "## Inference, diagnostics\n",
    "\n",
    "Having finished the simulations, we can continue by training the estimator and constructing the posterior. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c3698e2-0cab-4e14-844b-a5afa22036a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tvb_inversion.sbi import EstimatorSBI\n",
    "\n",
    "estimator = EstimatorSBI(prior, seq=seq, metrics=metrics)\n",
    "summ_stats = estimator.load_summary_stats('results.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b9ee2c-f78c-40ed-8015-17d42608241f",
   "metadata": {},
   "source": [
    "Next we train the estimator on the summary statistics of the simulated data features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a2fa020-2111-4eb4-8350-5e72b9096c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "posterior = estimator.train(summ_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac906ce-efec-412b-9afe-9bd01a21d85b",
   "metadata": {},
   "source": [
    "The trained estimator now can in turn be used to sample from the posterior given the summary statistics of the empirical data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "706a9517-3e50-4e97-9b5e-28a8a967203d",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 20_000\n",
    "posterior_samples = posterior.sample((num_samples,), obs_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f692102-c578-4648-879d-475fe6fcacbd",
   "metadata": {},
   "source": [
    "And finally, to assess the result, we can compute the posterior shrinkage -- a diagnostic value saying how much the empirical data is able to inform the value of the parameters of interest. Ideally, this value is close to 1 indicating a well identified posterior:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a330c26-1529-4f32-8f8c-0f5d3e5ff050",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from tvb_inversion.sbi.inference import shrinkage, zscore\n",
    "\n",
    "post_std = torch.std(posterior_samples)\n",
    "post_mean = torch.mean(posterior_samples)\n",
    "\n",
    "shr = shrinkage(prior_std, post_std)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
